{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "import json\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNonSeqData(data):\n",
    "    output = []\n",
    "\n",
    "    output.append(data['FurLength'])\n",
    "    output.append(data['Color1'])\n",
    "    output.append(0 if data['Fee'] == 0 else 1)\n",
    "    output.append(data['Vaccinated'])\n",
    "    output.append(data['Dewormed'])\n",
    "    output.append(data['Sterilized'])\n",
    "    output.append(data['MaturitySize'])\n",
    "    output.append(1 if data['Quantity'] == 1 else 2)\n",
    "    output.append(int(data['PhotoAmt']//5))\n",
    "    output.append(data['Gender'])\n",
    "    output.append(data['Age']//12)\n",
    "    output.append(0 if data['Breed2'] == 0 else 1)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 0, 0, 9, 0, 6, 15, 0, 0, 0, 8, 18, 20, 4, 0, 0, 0, 19, 0, 0, 17, 0, 1, 24, 7, 0, 23, 16, 0, 13, 14, 21, 22, 5, 2, 2, 0, 1, 1, 1, 2, 1, 0, 2, 0, 1]\n",
      "[0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "filename = 'text_and_label_all/json_vectorized_categorical.json'\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "with open(filename) as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "    for key, value in data.items():\n",
    "        X.append(value[\"vectorized\"][:-12] + getNonSeqData(value))\n",
    "        y.append(value[\"label\"])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "        \n",
    "y = to_categorical(y, num_classes=5)\n",
    "        \n",
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = 5000\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11447, 500) (11447, 12) (11447, 5)\n",
      "(2862, 500) (2862, 12) (2862, 5)\n"
     ]
    }
   ],
   "source": [
    "# truncate and pad input sequences\n",
    "input_len = 512\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=input_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=input_len)\n",
    "\n",
    "X_train_seq = X_train[:, :-12]\n",
    "X_train_other = X_train[:, -12:]\n",
    "\n",
    "X_test_seq = X_test[:, :-12]\n",
    "X_test_other = X_test[:, -12:]\n",
    "\n",
    "print(X_train_seq.shape, X_train_other.shape, y_train.shape)\n",
    "print(X_test_seq.shape, X_test_other.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 500, 32)      160000      input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 500, 32)      3104        embedding_15[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 250, 32)      0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 20)           260         input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_13 (LSTM)                  (None, 100)          53200       max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 20)           420         dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 120)          0           lstm_13[0][0]                    \n",
      "                                                                 dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 5)            605         concatenate_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 217,589\n",
      "Trainable params: 217,589\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vecor_length = 32\n",
    "seq_len = 500\n",
    "\n",
    "# seq data input\n",
    "visible1 = Input(shape=(seq_len,))\n",
    "embedding1 = Embedding(top_words, embedding_vecor_length, input_length=seq_len)(visible1)\n",
    "conv1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(embedding1)\n",
    "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "lstm1 = LSTM(100)(pool1)\n",
    "\n",
    "# non-seq data input\n",
    "visible2 = Input(shape=(12,))\n",
    "dense1 = Dense(20, activation='relu')(visible2)\n",
    "dense2 = Dense(20, activation='relu')(dense1)\n",
    "\n",
    "# merge input models\n",
    "merge1 = concatenate([lstm1, dense2])\n",
    "\n",
    "output = Dense(5, activation='softmax')(merge1)\n",
    "model = Model(inputs=[visible1, visible2], outputs=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11447/11447 [==============================] - 71s 6ms/step - loss: 1.4606 - acc: 0.2925\n",
      "Epoch 2/10\n",
      "11447/11447 [==============================] - 74s 6ms/step - loss: 1.3856 - acc: 0.3729\n",
      "Epoch 3/10\n",
      "11447/11447 [==============================] - 73s 6ms/step - loss: 1.2850 - acc: 0.4343\n",
      "Epoch 4/10\n",
      "11447/11447 [==============================] - 74s 6ms/step - loss: 1.1829 - acc: 0.4965\n",
      "Epoch 5/10\n",
      "11447/11447 [==============================] - 78s 7ms/step - loss: 1.0789 - acc: 0.5537\n",
      "Epoch 6/10\n",
      " 2240/11447 [====>.........................] - ETA: 59s - loss: 0.9555 - acc: 0.6107"
     ]
    }
   ],
   "source": [
    "model.fit([X_train_seq, X_train_other], y_train, epochs=10, batch_size=32)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
