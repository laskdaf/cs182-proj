{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "import json\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNonSeqData(data):\n",
    "    output = []\n",
    "\n",
    "    output.append(data['FurLength'])\n",
    "    output.append(data['Color1'])\n",
    "    \n",
    "#     output.append(0 if data['Fee'] == 0 else 1)\n",
    "    output.append(data['Fee'])\n",
    "    \n",
    "    output.append(data['Vaccinated'])\n",
    "    output.append(data['Dewormed'])\n",
    "    output.append(data['Sterilized'])\n",
    "    output.append(data['MaturitySize'])\n",
    "    \n",
    "#     output.append(1 if data['Quantity'] == 1 else 2)\n",
    "#     output.append(int(data['PhotoAmt']//5))\n",
    "    output.append(data['Quantity'])\n",
    "    output.append(data['PhotoAmt'])\n",
    "    \n",
    "    output.append(data['Gender'])\n",
    "    \n",
    "#     output.append(data['Age']//12)\n",
    "    output.append(data['Age'])\n",
    "\n",
    "    output.append(0 if data['Breed2'] == 0 else 1)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 0, 0, 9, 0, 6, 15, 0, 0, 0, 8, 18, 20, 4, 0, 0, 0, 19, 0, 0, 17, 0, 1, 24, 7, 0, 23, 16, 0, 13, 14, 21, 22, 5, 2, 2, 0, 1, 1, 1, 2, 1, 2.0, 2, 3, 1]\n",
      "[0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "filename = 'text_and_label_all/json_vectorized_categorical.json'\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "with open(filename) as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "    for key, value in data.items():\n",
    "        X.append(value[\"vectorized\"][:-12] + getNonSeqData(value))\n",
    "        y.append(value[\"label\"])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "        \n",
    "y = to_categorical(y, num_classes=5)\n",
    "        \n",
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = 5000\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11447, 500) (11447, 12) (11447, 5)\n",
      "(2862, 500) (2862, 12) (2862, 5)\n"
     ]
    }
   ],
   "source": [
    "# truncate and pad input sequences\n",
    "input_len = 512\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=input_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=input_len)\n",
    "\n",
    "X_train_seq = X_train[:, :-12]\n",
    "X_train_other = X_train[:, -12:]\n",
    "\n",
    "X_test_seq = X_test[:, :-12]\n",
    "X_test_other = X_test[:, -12:]\n",
    "\n",
    "print(X_train_seq.shape, X_train_other.shape, y_train.shape)\n",
    "print(X_test_seq.shape, X_test_other.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_16 (Embedding)        (None, 500, 32)      160000      input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 500, 32)      3104        embedding_16[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 250, 32)      0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 20)           260         input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_14 (LSTM)                  (None, 100)          53200       max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 20)           420         dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 120)          0           lstm_14[0][0]                    \n",
      "                                                                 dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 5)            605         concatenate_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 217,589\n",
      "Trainable params: 217,589\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vecor_length = 32\n",
    "seq_len = 500\n",
    "\n",
    "# seq data input\n",
    "visible1 = Input(shape=(seq_len,))\n",
    "embedding1 = Embedding(top_words, embedding_vecor_length, input_length=seq_len)(visible1)\n",
    "conv1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(embedding1)\n",
    "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "lstm1 = LSTM(100)(pool1)\n",
    "\n",
    "# non-seq data input\n",
    "visible2 = Input(shape=(12,))\n",
    "dense1 = Dense(20, activation='relu')(visible2)\n",
    "dense2 = Dense(20, activation='relu')(dense1)\n",
    "\n",
    "# merge input models\n",
    "merge1 = concatenate([lstm1, dense2])\n",
    "\n",
    "output = Dense(5, activation='softmax')(merge1)\n",
    "model = Model(inputs=[visible1, visible2], outputs=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11447/11447 [==============================] - 151s 13ms/step - loss: 1.5445 - acc: 0.3210\n",
      "Epoch 2/5\n",
      "11447/11447 [==============================] - 150s 13ms/step - loss: 1.3927 - acc: 0.3869\n",
      "Epoch 3/5\n",
      "11447/11447 [==============================] - 147s 13ms/step - loss: 1.2997 - acc: 0.4447\n",
      "Epoch 4/5\n",
      "11447/11447 [==============================] - 145s 13ms/step - loss: 1.1795 - acc: 0.5022\n",
      "Epoch 5/5\n",
      "11447/11447 [==============================] - 145s 13ms/step - loss: 1.0697 - acc: 0.5579\n",
      "Accuracy: 36.20%\n"
     ]
    }
   ],
   "source": [
    "model.fit([X_train_seq, X_train_other], y_train, epochs=5, batch_size=16)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate([X_test_seq, X_test_other], y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"models/multi_input_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"models/multi_input_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11447 samples, validate on 2862 samples\n",
      "Epoch 1/5\n",
      "11447/11447 [==============================] - 147s 13ms/step - loss: 0.9177 - acc: 0.6344 - val_loss: 1.7459 - val_acc: 0.3421\n",
      "Epoch 2/5\n",
      "11447/11447 [==============================] - 150s 13ms/step - loss: 0.8025 - acc: 0.6831 - val_loss: 1.8933 - val_acc: 0.3543\n",
      "Epoch 3/5\n",
      "11447/11447 [==============================] - 151s 13ms/step - loss: 0.6932 - acc: 0.7306 - val_loss: 2.0439 - val_acc: 0.3532\n",
      "Epoch 4/5\n",
      "11447/11447 [==============================] - 2293s 200ms/step - loss: 0.6009 - acc: 0.7707 - val_loss: 2.2066 - val_acc: 0.3532\n",
      "Epoch 5/5\n",
      "  528/11447 [>.............................] - ETA: 2:13 - loss: 0.4844 - acc: 0.8087"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "history = model.fit([X_train_seq, X_train_other], y_train, epochs=5, batch_size=16, validation_data=([X_test_seq, X_test_other], y_test))\n",
    "\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
